{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy as sc\n",
    "import scipy.sparse as sp\n",
    "import itertools\n",
    "\n",
    "from hypernetx.extras import lesmis as lm\n",
    "import matplotlib.pyplot as plt\n",
    "import pygenstability as pgs\n",
    "from pygenstability import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypernetx as hnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct random walk matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_laplacian(H):\n",
    "    \n",
    "    \"\"\" Construct Laplacian for HyperGraph H\n",
    "    \n",
    "    Arguments\n",
    "    H : Hypernetx hypergraph object\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    incidence = H.incidence_matrix().toarray()\n",
    "    \n",
    "    # hyperedge adjacency matrix\n",
    "    C = np.matmul(incidence.T,incidence)\n",
    "    A = np.matmul(incidence,incidence.T)\n",
    "\n",
    "    R = np.matmul(incidence, np.matmul(np.diag(np.diag(C)),incidence.T))\n",
    "\n",
    "    # defining transition matrix\n",
    "    L = R - A\n",
    "    np.fill_diagonal(L,0)\n",
    "    np.fill_diagonal(L,-np.sum(L,axis=0)[:,None])\n",
    "    L\n",
    "    \n",
    "    return L\n",
    "  \n",
    "def get_transition_matrix(H):\n",
    "    \n",
    "    \"\"\" Construct Laplacian for HyperGraph H\n",
    "    \n",
    "    Arguments\n",
    "    H : Hypernetx hypergraph object\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    incidence = H.incidence_matrix().toarray()\n",
    "    \n",
    "    # hyperedge adjacency matrix\n",
    "    C = np.matmul(incidence.T,incidence)\n",
    "    A = np.matmul(incidence,incidence.T)\n",
    "\n",
    "    R = np.matmul(incidence, np.matmul(np.diag(np.diag(C)),incidence.T))\n",
    "\n",
    "    # defining transition matrix\n",
    "    T = R - A\n",
    "    np.fill_diagonal(T,0)\n",
    "    T = T/np.sum(T,axis=0)[:,None]\n",
    "    \n",
    "    return T\n",
    "\n",
    "def get_adjacency(H):\n",
    "    \n",
    "    \"\"\" Construct Laplacian for HyperGraph H\n",
    "    \n",
    "    Arguments\n",
    "    H : Hypernetx hypergraph object\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    incidence = H.incidence_matrix().toarray()\n",
    "    \n",
    "    # hyperedge adjacency matrix\n",
    "    C = np.matmul(incidence.T,incidence)\n",
    "    A = np.matmul(incidence,incidence.T)\n",
    "\n",
    "    R = np.matmul(incidence, np.matmul(np.diag(np.diag(C)),incidence.T))\n",
    "\n",
    "    # defining transition matrix\n",
    "    adj = R - A\n",
    "    np.fill_diagonal(adj,0)\n",
    "\n",
    "    \n",
    "    return adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = {\n",
    "    0: ('a', 'b', 'c'),\n",
    "    1: ('c', 'd',),\n",
    "    2: ('a','b',)\n",
    "    \n",
    "}\n",
    "\n",
    "H = hnx.Hypergraph(scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnx.draw(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HD = H.dual()\n",
    "hnx.draw(HD)\n",
    "H.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = get_laplacian(H)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = get_transition_matrix(H)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_adjacency(H)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-hypergraph adjacency matrix\n",
    "incidence = H.incidence_matrix().toarray()    \n",
    "A_ = np.matmul(incidence,incidence.T)\n",
    "np.fill_diagonal(A_,0)\n",
    "A_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to subgraph of Les Mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = {\n",
    "    0: ('FN', 'TH'),\n",
    "    1: ('TH', 'JV'),\n",
    "    2: ('BM', 'FN', 'JA'),\n",
    "    3: ('JV', 'JU', 'CH', 'BM'),\n",
    "    4: ('JU', 'CH', 'BR', 'CN', 'CC', 'JV', 'BM'),\n",
    "    5: ('TH', 'GP'),\n",
    "    6: ('GP', 'MP'),\n",
    "    7: ('MA', 'GP')\n",
    "}\n",
    "\n",
    "H = hnx.Hypergraph(scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnx.draw(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = get_laplacian(H)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = get_transition_matrix(H)\n",
    "T.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = get_adjacency(H)\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = sp.csr_matrix(adj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Stability on Les Mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = lm.volumes;\n",
    "### List of Characters\n",
    "names = lm.df_names.set_index('Symbol');\n",
    "scenes = lm.df_scenes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct the edges as a dictionary named by the name of the Volume\n",
    "volume_edges = dict()\n",
    "for v in range(1,6):\n",
    "    volume_edges[v] = set(scenes.loc[scenes.Volume == v]['Characters'])\n",
    "    \n",
    "### Construct a hypergraph made up of volume_edges\n",
    "H = hnx.Hypergraph(volume_edges,name='Volumes')\n",
    "for node in H.nodes:\n",
    "    H.nodes[node].name = names.loc[node]['FullName']\n",
    "    H.nodes[node].description = names.loc[node]['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the Hypergraph\n",
    "def noborder(width=10,height=10):\n",
    "    fig = plt.figure(figsize=[width,height])\n",
    "    ax = plt.gca()\n",
    "    ax.axis('off')\n",
    "noborder()\n",
    "hnx.draw(H)\n",
    "\n",
    "\n",
    "# construct projected matrix (no hyperedges)\n",
    "incidence = H.incidence_matrix().toarray()    \n",
    "A_ = np.matmul(incidence,incidence.T)\n",
    "np.fill_diagonal(A_,0)\n",
    "A_ = sp.csr_matrix(A_)\n",
    "\n",
    "# construct network object just for plotting\n",
    "g = nx.Graph(A_)\n",
    "pos = nx.spring_layout(g, weight=None, scale=1)\n",
    "for u in g:\n",
    "    g.nodes[u][\"pos\"] = pos[u]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = {\n",
    "    0: ('1','2','3','4'),\n",
    "    1: ('5','6','7','8'),\n",
    "    2: ('9','10','11','12'),\n",
    "    3: ('13','14','15','16'), \n",
    "    4: ('2','5'),\n",
    "    5: ('4','7'),\n",
    "    6: ('2','7'),\n",
    "    7: ('4','5'),\n",
    "    8: ('7','13'),\n",
    "    9: ('8','14'),\n",
    "    10: ('7','14'),\n",
    "    11: ('13','8'),\n",
    "    12: ('3','9'),\n",
    "    13: ('4','10'),\n",
    "    14: ('3','10'),\n",
    "    15: ('4','9'),\n",
    "    16: ('10','13'),\n",
    "    17: ('12','15'),\n",
    "    18: ('10','15'),\n",
    "    19: ('12','13'),\n",
    "    20: ('4','13'),\n",
    "    21: ('7','10')\n",
    "}\n",
    "\n",
    "H = hnx.Hypergraph(edges)\n",
    "hnx.draw(H)\n",
    "\n",
    "\n",
    "# adjacency matrix constructed using Carletti method\n",
    "graph = sp.csr_matrix(get_adjacency(H))\n",
    "\n",
    "# construct projected matrix (no hyperedges)\n",
    "incidence = H.incidence_matrix().toarray()    \n",
    "A_ = np.matmul(incidence,incidence.T)\n",
    "np.fill_diagonal(A_,0)\n",
    "A_ = sp.csr_matrix(A_)\n",
    "\n",
    "# construct network object just for plotting\n",
    "g = nx.Graph(A_)\n",
    "pos = nx.spring_layout(g, weight=None, scale=1)\n",
    "for u in g:\n",
    "    g.nodes[u][\"pos\"] = pos[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_hypergraph = pgs.run(graph, min_time=-2, max_time=1, n_time=50, constructor='continuous_combinatorial')\n",
    "plotting.plot_scan(results_hypergraph)\n",
    "plt.figure()\n",
    "plotting.plot_single_community(g, results_hypergraph,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard adjacency matrix\n",
    "\n",
    "results_projected = pgs.run(A_, min_time=-2, max_time=1, n_time=50, constructor='continuous_combinatorial')\n",
    "plotting.plot_scan(results_projected)\n",
    "plt.figure()\n",
    "plotting.plot_single_community(g, results_projected,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Example 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = {\n",
    "    0: ('2','3','7','8'),\n",
    "    1: ('4','5','9','10'),\n",
    "    2: ('1','2'),\n",
    "    3: ('6','7'), \n",
    "    4: ('1','7'),\n",
    "    5: ('6','2'),\n",
    "    6: ('3','4'),\n",
    "    7: ('8','9'),\n",
    "    8: ('3','9'),\n",
    "    9: ('4','8'),\n",
    "    10: ('1','6')\n",
    "}\n",
    "\n",
    "H = hnx.Hypergraph(edges)\n",
    "hnx.draw(H)\n",
    "\n",
    "\n",
    "# adjacency matrix constructed using Carletti method\n",
    "graph = sp.csr_matrix(get_adjacency(H))\n",
    "\n",
    "# construct projected matrix (no hyperedges)\n",
    "incidence = H.incidence_matrix().toarray()    \n",
    "A_ = np.matmul(incidence,incidence.T)\n",
    "np.fill_diagonal(A_,0)\n",
    "A_ = sp.csr_matrix(A_)\n",
    "\n",
    "# construct network object just for plotting\n",
    "g = nx.Graph(A_)\n",
    "pos = nx.spring_layout(g, weight=None, scale=1)\n",
    "for u in g:\n",
    "    g.nodes[u][\"pos\"] = pos[u]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hypergraph = pgs.run(graph, min_time=-2, max_time=1, n_time=50, constructor='continuous_combinatorial')\n",
    "plotting.plot_scan(results_hypergraph)\n",
    "plt.figure()\n",
    "plotting.plot_single_community(g, results_hypergraph,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard adjacency matrix\n",
    "\n",
    "results_projected = pgs.run(A_, min_time=-2, max_time=1, n_time=50, constructor='continuous_combinatorial')\n",
    "plotting.plot_scan(results_projected)\n",
    "plt.figure()\n",
    "plotting.plot_single_community(g, results_projected,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic block model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "\n",
    "\n",
    "def joint_entropy(x,y):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a variable, or joint entropy of several variables.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array or list\n",
    "    y : array or list\n",
    "\n",
    "    \"\"\"\n",
    "    n_instances = len(x)\n",
    "    H = 0\n",
    "    X = [np.array(x),np.array(y)]\n",
    "    for classes in itertools.product(*[set(x) for x in X]):\n",
    "        v = np.array([True] * n_instances)\n",
    "        for predictions, c in zip(X, classes):\n",
    "            v = np.logical_and(v, predictions == c)\n",
    "        p = np.mean(v)\n",
    "        H += -p * np.log2(p) if p > 0 else 0\n",
    "    return H\n",
    "\n",
    "def entropy(labels):\n",
    "    \"\"\"Calculates the entropy for a labeling.\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : int array, shape = [n_samples]\n",
    "        The labels\n",
    "    Notes\n",
    "    -----\n",
    "    The logarithm used is the natural logarithm (base-e).\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        return 1.0\n",
    "    label_idx = np.unique(labels, return_inverse=True)[1]\n",
    "    pi = np.bincount(label_idx).astype(np.float64)\n",
    "    pi = pi[pi > 0]\n",
    "    pi_sum = np.sum(pi)\n",
    "    # log(a / b) should be calculated as log(a) - log(b) for\n",
    "    # possible loss of precision\n",
    "    return -np.sum((pi / pi_sum) * (np.log(pi) - np.log(pi_sum)))\n",
    "\n",
    "def vi_score(partition_1,partition_2):\n",
    "\n",
    "    MI = mutual_info_score(\n",
    "            partition_1,\n",
    "            partition_2,\n",
    "        )\n",
    "    Ex = entropy(partition_1)\n",
    "    Ey = entropy(partition_2)\n",
    "    JE = Ex + Ey - MI\n",
    "\n",
    "    return (JE - MI) / JE\n",
    "\n",
    "\n",
    "def construct_hypergraph_sbm(g):\n",
    "\n",
    "    cliques = list(nx.find_cliques(g))\n",
    "    cli = cliques\n",
    "\n",
    "        #cli = [edge for edge in cli if len(edge)>2]\n",
    "\n",
    "    cli.sort(key=len)\n",
    "    cli.reverse()\n",
    "\n",
    "    h_block_edges = []\n",
    "\n",
    "\n",
    "    for edge in cli:\n",
    "        blocks = [g.nodes[node]['block'] for node in edge]\n",
    "        if blocks.count(blocks[0]) == len(blocks):\n",
    "            h_block_edges.append(edge)\n",
    "\n",
    "\n",
    "    cli = h_block_edges + [edge for edge in cliques if len(edge)<3]\n",
    "\n",
    "    # this removal section needs fixing!!!!!\n",
    "    h_edges = []\n",
    "    while len(cli)>0:\n",
    "        edge = cli[0]#cli[np.random.randint(len(cli),size = 1)[0]]\n",
    "        for e in cli:\n",
    "            intersect = list(set(e) & set(edge)) \n",
    "            if len(intersect)>1:    \n",
    "                cli.remove(e)\n",
    "\n",
    "        h_edges.append(tuple(edge))\n",
    "\n",
    "    a = np.linspace(0, len(h_edges)-1, len(h_edges))\n",
    "    a = [str(int(x)) for x in a]\n",
    "\n",
    "\n",
    "    h_edge_list = dict(zip(a, h_edges))\n",
    "    H = hnx.Hypergraph(h_edge_list)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ps = np.linspace(0.1,0.5,10)\n",
    "\n",
    "sizes = [20,20,20]\n",
    "p1 = 0.9\n",
    "\n",
    "vi_scores_projected = []\n",
    "vi_scores_hypergraph = []\n",
    "\n",
    "for p2  in ps:\n",
    "    probs = [[p1, p2, p2], [p2, p1, p2], [p2, p2, p1]]\n",
    "    g = nx.stochastic_block_model(sizes, probs, seed=0)\n",
    "    #nx.draw(g)\n",
    "    H = construct_hypergraph_sbm(g)\n",
    "    \n",
    "    # adjacency matrix constructed using Carletti method\n",
    "    graph = sp.csr_matrix(get_adjacency(H))\n",
    "\n",
    "    # construct projected matrix (no hyperedges)\n",
    "    incidence = H.incidence_matrix().toarray()    \n",
    "    A_ = np.matmul(incidence,incidence.T)\n",
    "    np.fill_diagonal(A_,0)\n",
    "    A_ = sp.csr_matrix(A_)\n",
    "    \n",
    "    # construct network object just for plottin\n",
    "        \n",
    "    gt_partition = [g.nodes[node]['block'] for node in g]\n",
    "        \n",
    "    results_hypergraph = pgs.run(graph, min_time=-1, max_time=1.5, n_time=50, constructor='continuous_combinatorial')\n",
    "    comms = np.array(results_hypergraph['number_of_communities'])\n",
    "    idx = np.where(comms==3)[0] # take first index\n",
    "    vi = []\n",
    "    for i in idx:        \n",
    "        partition_hypergraph = results_hypergraph['community_id'][i] \n",
    "        vi.append(vi_score(partition_hypergraph,gt_partition))\n",
    "    vi_scores_hypergraph.append(np.median(vi))\n",
    "    \n",
    "    \n",
    "    results_projected = pgs.run(A_, min_time=-1, max_time=1.5, n_time=50, constructor='continuous_combinatorial')\n",
    "    comms = np.array(results_hypergraph['number_of_communities'])\n",
    "    idx = np.where(comms==3)[0] # take first index\n",
    "    vi = []\n",
    "    for i in idx:        \n",
    "        partition_projected = results_projected['community_id'][i] \n",
    "        vi.append(vi_score(partition_projected,gt_partition))\n",
    "    vi_scores_projected.append(np.median(vi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ps,vi_scores_hypergraph)\n",
    "plt.plot(ps,vi_scores_projected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [4,4]\n",
    "\n",
    "p1 = 1\n",
    "p2 = 0.05\n",
    "#probs = [[p1, p2, p2], [p2, p1, p2], [p2, p2, p1]]\n",
    "p = [[p1, p2,],[p2, p1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "nodelist = range(0, sum(sizes))\n",
    "block_range = range(len(sizes))\n",
    "g = nx.Graph()\n",
    "block_iter = itertools.combinations_with_replacement(block_range, 2)\n",
    "    # Split nodelist in a partition (list of sets).\n",
    "size_cumsum = [sum(sizes[0:x]) for x in range(0, len(sizes) + 1)]\n",
    "g.graph[\"partition\"] = [\n",
    "        set(nodelist[size_cumsum[x] : size_cumsum[x + 1]])\n",
    "        for x in range(0, len(size_cumsum) - 1)\n",
    "    ]\n",
    "    # Setup nodes and graph name\n",
    "for block_id, nodes in enumerate(g.graph[\"partition\"]):\n",
    "    for node in nodes:\n",
    "        g.add_node(node, block=block_id)\n",
    "\n",
    "g.name = \"hypergraph_stochastic_block_model\"\n",
    "\n",
    "    # Test for edge existence\n",
    "parts = g.graph[\"partition\"]\n",
    "for i, j in block_iter:\n",
    "        edges = itertools.product(parts[i], parts[j])             \n",
    "\n",
    "        for e in edges:\n",
    "            if random.uniform(0, 1) < p[i][j]:\n",
    "                g.add_edge(*e)  # __safe  \n",
    "                \n",
    "nx.draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [4,4]\n",
    "\n",
    "p1 = 1\n",
    "p2 = 0.05\n",
    "#probs = [[p1, p2, p2], [p2, p1, p2], [p2, p2, p1]]\n",
    "probs = [[p1, p2,],[p2, p1]]\n",
    "\n",
    "\n",
    "g = nx.stochastic_block_model(sizes, probs, seed=0)\n",
    "\n",
    "\n",
    "nx.draw(g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques = list(nx.find_cliques(g))\n",
    "h_block_edges = []\n",
    "for edge in cliques:\n",
    "    blocks = [g.nodes[node]['block'] for node in edge]\n",
    "    \n",
    "    if blocks.count(blocks[0]) == len(blocks):\n",
    "        h_block_edges.append(edge)\n",
    "        \n",
    "h_block_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in h_block_edges:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for e in cli:\n",
    "    intersect = list(set(e) & set(edge))\n",
    "    print(len(intersect))\n",
    "    if len(intersect)>1: \n",
    "        print(e)\n",
    "        cli.remove(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cli)\n",
    "edge = cli[0]#cli[np.random.randint(len(cli),size = 1)[0]]\n",
    "print(edge)\n",
    "print(len(cli))\n",
    "\n",
    "cli_c = cli\n",
    "\n",
    "for e in cli:\n",
    "    intersect = list(set(e) & set(edge))\n",
    "    print(len(intersect))\n",
    "    if len(intersect)>1: \n",
    "        print(e)\n",
    "        cli.remove(e)\n",
    "\n",
    "        \n",
    "print(cli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h_edges = []\n",
    "while len(cli)>0:\n",
    "    edge = cli[0]#cli[np.random.randint(len(cli),size = 1)[0]]\n",
    "    print(edge)\n",
    "    for e in cli:\n",
    "        intersect = list(set(e) & set(edge)) \n",
    "        if len(intersect)>1:    \n",
    "            cli.remove(e)\n",
    "\n",
    "    h_edges.append(tuple(edge))\n",
    "\n",
    "a = np.linspace(0, len(h_edges)-1, len(h_edges))\n",
    "a = [str(int(x)) for x in a]\n",
    "\n",
    "\n",
    "h_edge_list = dict(zip(a, h_edges))\n",
    "H = hnx.Hypergraph(h_edge_list)\n",
    "\n",
    "nx.draw(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.number_of_edges(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
